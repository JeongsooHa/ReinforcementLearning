{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from random import *\n",
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# np.set_printoptions(precision=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mat = np.random.random((16,10))\n",
    "# mat = torch.tensor(dist, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 0., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 1., 1., 0., 1., 0., 1., 1.],\n",
       "       [1., 1., 1., 0., 1., 1., 1., 1., 0., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "       [1., 1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [0., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1., 0., 1., 0., 1., 1., 1.],\n",
       "       [1., 1., 0., 1., 1., 1., 1., 1., 1., 0.],\n",
       "       [1., 0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       [1., 0., 0., 1., 1., 1., 1., 0., 1., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 0., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 1., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a mask\n",
    "mask = np.ones((16,10))\n",
    "\n",
    "for i in range(30):\n",
    "    x = randint(0, 15)\n",
    "    y = randint(0, 9)\n",
    "    mask[x][y] = 0\n",
    "\n",
    "mask[2][1] = 0\n",
    "mask[2][2] = 0\n",
    "mask[2][5] = 0\n",
    "mask[2][7] = 0\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_mat_t = torch.tensor(mat, dtype=torch.float)\n",
    "# please check for one task!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4989, 0.9783, 0.3794, 0.0595, 0.2303, 0.3737, 0.0103, 0.7360, 0.9513,\n",
      "        0.7373])\n",
      "[0. 0. 0. 1. 1. 0. 1. 0. 1. 1.]\n",
      "[[0.87425561 0.4501916  0.         0.99851745 0.51063018 0.4588697\n",
      "  0.07142779 0.59342145 0.57982774 0.        ]\n",
      " [0.80830413 0.52995262 0.63148643 0.         0.59537586 0.0553945\n",
      "  0.15503988 0.63831609 0.92222088 0.88347504]\n",
      " [0.         0.         0.         0.05948534 0.23031696 0.\n",
      "  0.01030761 0.         0.95130108 0.73733963]\n",
      " [0.01573541 0.56244622 0.7784028  0.         0.02534604 0.75884412\n",
      "  0.58916362 0.82123686 0.         0.84441432]\n",
      " [0.38211952 0.29060636 0.75801939 0.40467691 0.58272994 0.91294359\n",
      "  0.55822158 0.24049484 0.         0.28412306]\n",
      " [0.67700798 0.92503246 0.30316933 0.00732718 0.80007517 0.79577291\n",
      "  0.49677133 0.29719074 0.         0.51895282]\n",
      " [0.         0.79041712 0.61092002 0.89469253 0.54479647 0.56269912\n",
      "  0.15217598 0.67362202 0.         0.08872634]\n",
      " [0.06738254 0.30081426 0.         0.88406261 0.09278739 0.71858903\n",
      "  0.78851587 0.66091941 0.64821099 0.46622732]\n",
      " [0.         0.85094047 0.91190449 0.14568223 0.1182563  0.11200461\n",
      "  0.17966169 0.33814355 0.18535051 0.96855808]\n",
      " [0.37003166 0.93338583 0.75879367 0.43355276 0.00354173 0.59081148\n",
      "  0.5063773  0.26277726 0.71967294 0.61326212]\n",
      " [0.35945471 0.87432813 0.55464674 0.8982057  0.         0.14794412\n",
      "  0.         0.31099298 0.15731617 0.83259801]\n",
      " [0.43473594 0.54932844 0.         0.60631619 0.59833185 0.63229566\n",
      "  0.36598206 0.93413519 0.29301681 0.        ]\n",
      " [0.31647919 0.         0.90738227 0.42075747 0.71956626 0.92468088\n",
      "  0.32262575 0.33127135 0.33763191 0.83249256]\n",
      " [0.62789541 0.         0.         0.16376774 0.96942097 0.75262011\n",
      "  0.53737484 0.         0.93086951 0.        ]\n",
      " [0.77464526 0.1938534  0.0248976  0.65207049 0.57319536 0.12122179\n",
      "  0.         0.80872785 0.         0.        ]\n",
      " [0.15418687 0.34687133 0.96376586 0.93383006 0.30103857 0.41606132\n",
      "  0.         0.         0.63632377 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Choose a task in a job.\n",
    "print(new_mat_t[2])\n",
    "print(mask[2])\n",
    "\n",
    "masked_mat = np.multiply(mat, mask)\n",
    "# masked_mat_t = torch.tensor(masked_mat, dtype=torch.float\n",
    "# masked_mat_t = torch.tensor(np.multiply(mat[2], mask[2]), dtype = torch.float)\n",
    "# print(masked_mat_t)\n",
    "print(masked_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(masked_mat)\n",
    "masked_mat_scaled = min_max_scaler.fit_transform(masked_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_masked_mat_scaled = np.ones((16,10))\n",
    "for i in range(len(masked_mat_scaled)):\n",
    "    t = np.sum(masked_mat_scaled[i])\n",
    "    _masked_mat_scaled[i] = masked_mat_scaled[i]/t\n",
    "print(_masked_mat_scaled)\n",
    "for i in range(len(_masked_mat_scaled)):\n",
    "    rowsum = np.sum(_masked_mat_scaled[i])\n",
    "    print(rowsum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "masked_mat_scaled_t = torch.tensor(_masked_mat_scaled, dtype=torch.float)\n",
    "for t in range(100):\n",
    "    t = masked_mat_scaled_t.multinomial(num_samples=1)\n",
    "\n",
    "    masked_mat_scaled_n = np.array(masked_mat_scaled_t)\n",
    "    t_n = np.array(t)\n",
    "    #print(masked_mat_scaled_n)\n",
    "    print(t_n.reshape(1,16))\n",
    "    for i in range(100):\n",
    "        for j in range(len(masked_mat_scaled_n)):\n",
    "            if masked_mat_scaled_n[j][t_n[j]] == 0:\n",
    "                print(\"!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.8017\n",
      "[0.0586 0.0726 0.0865 0.0633 0.0283 0.0411 0.01   0.0253 0.0349 0.0287]\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "#  only for one task.  #\n",
    "########################\n",
    "n_mat = np.array([-2.7531, -2.7391, -2.7252, -2.7484, -2.7834, -2.7706, -2.8017, -2.7864, -2.7768, -2.7830])\n",
    "min_v = min(n_mat)\n",
    "print(min_v)\n",
    "n_mat = n_mat-min_v+0.01\n",
    "print(n_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mat_t = torch.tensor(n_mat, dtype=torch.float)\n",
    "masked_mat_re = np.reshape(new_mat_t,(-1,1))\n",
    "\n",
    "transformer = Normalizer().fit(masked_mat_re)\n",
    "masked_mat_scaled_re = transformer.transform(masked_mat_re)\n",
    "print(masked_mat_scaled_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mat_t[2] = torch.tensor(n_mat, dtype=torch.float)\n",
    "print(new_mat_t[2])\n",
    "print(type(new_mat_t[2]))\n",
    "print(mask[2])\n",
    "\n",
    "masked_mat = np.multiply(new_mat_t[2], mask[2])\n",
    "masked_mat_re = np.reshape(masked_mat,(-1,1))\n",
    "print(masked_mat)\n",
    "print(masked_mat_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-1.]\n",
      " [-1.]\n",
      " [-0.]\n",
      " [-1.]\n",
      " [-0.]\n",
      " [-0.]\n",
      " [-1.]]\n"
     ]
    }
   ],
   "source": [
    "# masked_mat_scaled_re = min_max_scaler.fit_transform(masked_mat_re)\n",
    "#masked_mat_scaled_re\n",
    "transformer = Normalizer().fit(masked_mat_re)\n",
    "masked_mat_scaled_re = transformer.transform(masked_mat_re)\n",
    "print(masked_mat_scaled_re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.058464756992105"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = np.sum(masked_mat_scaled_re[:])\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_masked_mat_scaled = np.ones((len(masked_mat_re),1))\n",
    "_masked_mat_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.07821569]\n",
      " [0.        ]\n",
      " [0.        ]\n",
      " [0.2024731 ]\n",
      " [0.26485999]\n",
      " [0.        ]\n",
      " [0.15812928]\n",
      " [0.        ]\n",
      " [0.08389893]\n",
      " [0.212423  ]]\n",
      "Check if sum is 1 ====  1.0\n"
     ]
    }
   ],
   "source": [
    "_masked_mat_scaled[:] = masked_mat_scaled_re[:]/t\n",
    "print(_masked_mat_scaled)\n",
    "print(\"Check if sum is 1 ==== \",np.sum(_masked_mat_scaled[:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0782, 0.0000, 0.0000, 0.2025, 0.2649, 0.0000, 0.1581, 0.0000, 0.0839,\n",
      "        0.2124])\n"
     ]
    }
   ],
   "source": [
    "_masked_mat_scaled_t = torch.tensor(_masked_mat_scaled, dtype=torch.float)\n",
    "_masked_mat_scaled_tre = np.reshape(_masked_mat_scaled_t,len(_masked_mat_scaled_t))\n",
    "print(_masked_mat_scaled_tre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([4])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "t = _masked_mat_scaled_tre.multinomial(num_samples=1)\n",
    "print(t)\n",
    "print(t[0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(1000):\n",
    "    t = _masked_mat_scaled_tre.multinomial(num_samples=1)\n",
    "    if _masked_mat_scaled_tre[t[0].item()] == 0:\n",
    "        print(\"!!!!!!!!!!!!!!!!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-cd7a97b5cc87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline \n",
    "import torch\n",
    "import torchvision.transforms.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.29897788 0.89864514 0.99766604 ... 0.39749961 0.52899936 0.22728527]\n",
      " [0.49788036 0.42616756 0.92585362 ... 0.47669379 0.88933529 0.11394485]\n",
      " [0.87931539 0.14511193 0.06418007 ... 0.66682744 0.29014925 0.13022923]\n",
      " ...\n",
      " [0.206438   0.87277499 0.62056648 ... 0.92428587 0.17225766 0.58424001]\n",
      " [0.52643797 0.33805272 0.53506457 ... 0.27139244 0.43899586 0.05739967]\n",
      " [0.51476429 0.25645613 0.52785158 ... 0.84680379 0.49049647 0.84563698]]\n"
     ]
    }
   ],
   "source": [
    "state = np.random.random((200, 200))\n",
    "print(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'add' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-8aaed9f97b2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: ufunc 'add' did not contain a loop with signature matching types dtype('<U32') dtype('<U32') dtype('<U32')"
     ]
    }
   ],
   "source": [
    "plt.show('/'+state+'.png', interpolation='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'stinkbug.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-5d51ab5fddfc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'stinkbug.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/reinforce/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1431\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1432\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1433\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1434\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mhandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'stinkbug.png'"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "img=mpimg.imread('stinkbug.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input type float64 is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-23926a3b9dad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/reinforce/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_pil_image\u001b[0;34m(pic, mode)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input type {} is not supported'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input type float64 is not supported"
     ]
    }
   ],
   "source": [
    "state = F.to_pil_image(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reinforce",
   "language": "python",
   "name": "reinforce"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
